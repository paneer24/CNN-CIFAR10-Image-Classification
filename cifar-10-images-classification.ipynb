{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7665,"sourceType":"datasetVersion","datasetId":5071},{"sourceId":9243,"sourceType":"datasetVersion","datasetId":2243},{"sourceId":15444,"sourceType":"datasetVersion","datasetId":11102}],"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸ“· Cifar-10 Image Classifiction\n\nThe `CIFAR-10` dataset consists of `60000` `32x32` color images in `10` classes, with `6000` images per class. There are `50000` training images and `10000` test images.\n\n# ðŸ”¬ Problem Definition:\n\nGiven an image, can we predict the correct class of this image?\n\nThe images are very small (`32x32`) and by visualizing them you will notice how difficult it is to distinguish them even for a human. \n\nIn this notebook we are going to build a CNN model that can classify images of various objects. We have `10` class of images:\n1. Airplane\n2. Automobile\n3. Bird\n4. Cat\n5. Deer\n6. Dog\n7. Frog\n8. Horse\n9. Ship\n10. Truck\n\n# ðŸŽ¯ Evaluation:\n\nWe have `10` classes, so if we pick a image and we randomly gues it class, we have `1/10` probability to be true.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nfrom sklearn.metrics import ConfusionMatrixDisplay\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:18:41.302421Z","iopub.execute_input":"2023-02-02T06:18:41.303329Z","iopub.status.idle":"2023-02-02T06:18:47.291433Z","shell.execute_reply.started":"2023-02-02T06:18:41.303165Z","shell.execute_reply":"2023-02-02T06:18:47.290465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“¥ Load the data","metadata":{}},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n\nprint(f\"X_train shape: {X_train.shape}\")\nprint(f\"y_train shape: {y_train.shape}\")\nprint(f\"X_test shape: {X_test.shape}\")\nprint(f\"y_test shape: {y_test.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:18:47.293483Z","iopub.execute_input":"2023-02-02T06:18:47.294114Z","iopub.status.idle":"2023-02-02T06:19:02.066127Z","shell.execute_reply.started":"2023-02-02T06:18:47.294076Z","shell.execute_reply":"2023-02-02T06:19:02.065088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ–¼ Data Visualization","metadata":{}},{"cell_type":"code","source":"# Define the labels of the dataset\nlabels = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n          'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Let's view more images in a grid format\n# Define the dimensions of the plot grid \nW_grid = 10\nL_grid = 10\n\n# fig, axes = plt.subplots(L_grid, W_grid)\n# subplot return the figure object and axes object\n# we can use the axes object to plot specific figures at various locations\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n\naxes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n\nn_train = len(X_train) # get the length of the train dataset\n\n# Select a random number from 0 to n_train\nfor i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n\n    # Select a random number\n    index = np.random.randint(0, n_train)\n    # read and display an image with the selected index    \n    axes[i].imshow(X_train[index,1:])\n    label_index = int(y_train[index])\n    axes[i].set_title(labels[label_index], fontsize = 8)\n    axes[i].axis('off')\n\nplt.subplots_adjust(hspace=0.4)","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:02.067491Z","iopub.execute_input":"2023-02-02T06:19:02.067802Z","iopub.status.idle":"2023-02-02T06:19:05.3899Z","shell.execute_reply.started":"2023-02-02T06:19:02.067774Z","shell.execute_reply":"2023-02-02T06:19:05.389087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes_name = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\nclasses, counts = np.unique(y_train, return_counts=True)\nplt.barh(classes_name, counts)\nplt.title('Class distribution in training set')","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:05.391761Z","iopub.execute_input":"2023-02-02T06:19:05.392071Z","iopub.status.idle":"2023-02-02T06:19:05.606856Z","shell.execute_reply.started":"2023-02-02T06:19:05.392041Z","shell.execute_reply":"2023-02-02T06:19:05.605946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classes, counts = np.unique(y_test, return_counts=True)\nplt.barh(classes_name, counts)\nplt.title('Class distribution in testing set')","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:05.608306Z","iopub.execute_input":"2023-02-02T06:19:05.608658Z","iopub.status.idle":"2023-02-02T06:19:06.018985Z","shell.execute_reply.started":"2023-02-02T06:19:05.608622Z","shell.execute_reply":"2023-02-02T06:19:06.017937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The class are equally distributed","metadata":{}},{"cell_type":"markdown","source":"# ðŸ”„ Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# Scale the data\nX_train = X_train / 255.0\nX_test = X_test / 255.0\n\n# Transform target variable into one-hotencoding\ny_cat_train = to_categorical(y_train, 10)\ny_cat_test = to_categorical(y_test, 10)","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:06.020699Z","iopub.execute_input":"2023-02-02T06:19:06.022744Z","iopub.status.idle":"2023-02-02T06:19:06.543995Z","shell.execute_reply.started":"2023-02-02T06:19:06.022696Z","shell.execute_reply":"2023-02-02T06:19:06.543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_cat_train","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:06.54567Z","iopub.execute_input":"2023-02-02T06:19:06.546073Z","iopub.status.idle":"2023-02-02T06:19:06.554428Z","shell.execute_reply.started":"2023-02-02T06:19:06.546015Z","shell.execute_reply":"2023-02-02T06:19:06.553542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ¤– Model Building","metadata":{}},{"cell_type":"code","source":"INPUT_SHAPE = (32, 32, 3)\nKERNEL_SIZE = (3, 3)\nmodel = Sequential()\n\n# Convolutional Layer\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=32, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\n# Pooling layer\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n# Dropout layers\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=64, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size=KERNEL_SIZE, input_shape=INPUT_SHAPE, activation='relu', padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n# model.add(Dropout(0.2))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10, activation='softmax'))\n\nMETRICS = [\n    'accuracy',\n    tf.keras.metrics.Precision(name='precision'),\n    tf.keras.metrics.Recall(name='recall')\n]\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=METRICS)","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:06.555849Z","iopub.execute_input":"2023-02-02T06:19:06.556436Z","iopub.status.idle":"2023-02-02T06:19:09.699392Z","shell.execute_reply.started":"2023-02-02T06:19:06.556402Z","shell.execute_reply":"2023-02-02T06:19:09.698389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:09.700851Z","iopub.execute_input":"2023-02-02T06:19:09.701483Z","iopub.status.idle":"2023-02-02T06:19:09.712107Z","shell.execute_reply.started":"2023-02-02T06:19:09.701445Z","shell.execute_reply":"2023-02-02T06:19:09.711068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Early Stopping","metadata":{}},{"cell_type":"code","source":"early_stop = EarlyStopping(monitor='val_loss', patience=2)","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:09.716781Z","iopub.execute_input":"2023-02-02T06:19:09.717079Z","iopub.status.idle":"2023-02-02T06:19:09.721905Z","shell.execute_reply.started":"2023-02-02T06:19:09.717049Z","shell.execute_reply":"2023-02-02T06:19:09.720811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentations","metadata":{}},{"cell_type":"code","source":"batch_size = 32\ndata_generator = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\ntrain_generator = data_generator.flow(X_train, y_cat_train, batch_size)\nsteps_per_epoch = X_train.shape[0] // batch_size\n\nr = model.fit(train_generator, \n              epochs=50,\n              steps_per_epoch=steps_per_epoch,\n              validation_data=(X_test, y_cat_test), \n#               callbacks=[early_stop],\n#               batch_size=batch_size,\n             )","metadata":{"execution":{"iopub.status.busy":"2023-02-02T06:19:09.723182Z","iopub.execute_input":"2023-02-02T06:19:09.724137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ðŸ“Š Model Evaluation","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12, 16))\n\nplt.subplot(4, 2, 1)\nplt.plot(r.history['loss'], label='Loss')\nplt.plot(r.history['val_loss'], label='val_Loss')\nplt.title('Loss Function Evolution')\nplt.legend()\n\nplt.subplot(4, 2, 2)\nplt.plot(r.history['accuracy'], label='accuracy')\nplt.plot(r.history['val_accuracy'], label='val_accuracy')\nplt.title('Accuracy Function Evolution')\nplt.legend()\n\nplt.subplot(4, 2, 3)\nplt.plot(r.history['precision'], label='precision')\nplt.plot(r.history['val_precision'], label='val_precision')\nplt.title('Precision Function Evolution')\nplt.legend()\n\nplt.subplot(4, 2, 4)\nplt.plot(r.history['recall'], label='recall')\nplt.plot(r.history['val_recall'], label='val_recall')\nplt.title('Recall Function Evolution')\nplt.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluation = model.evaluate(X_test, y_cat_test)\nprint(f'Test Accuracy : {evaluation[1] * 100:.2f}%')\n\ny_pred = model.predict(X_test)\ny_pred = np.argmax(y_pred, axis=1)\ncm = confusion_matrix(y_test, y_pred)\n\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm,\n                              display_labels=labels)\n\n\n# NOTE: Fill all variables here with default values of the plot_confusion_matrix\nfig, ax = plt.subplots(figsize=(10, 10))\ndisp = disp.plot(xticks_rotation='vertical', ax=ax,cmap='summer')\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(y_test, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test on one image","metadata":{}},{"cell_type":"code","source":"my_image = X_test[100]\nplt.imshow(my_image)\n\n# that's a Deer\nprint(f\" Image 100 is {y_test[100]}\")\n\n# correctly predicted as a Deer\npred_100 = np.argmax(model.predict(my_image.reshape(1, 32, 32, 3)))\nprint(f\"The model predict that image 100 is {pred_100}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the labels of the dataset\nlabels = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n          'dog', 'frog', 'horse', 'ship', 'truck']\n\n# Let's view more images in a grid format\n# Define the dimensions of the plot grid \nW_grid = 5\nL_grid = 5\n\n# fig, axes = plt.subplots(L_grid, W_grid)\n# subplot return the figure object and axes object\n# we can use the axes object to plot specific figures at various locations\n\nfig, axes = plt.subplots(L_grid, W_grid, figsize = (17,17))\n\naxes = axes.ravel() # flaten the 15 x 15 matrix into 225 array\n\nn_test = len(X_test) # get the length of the train dataset\n\n# Select a random number from 0 to n_train\nfor i in np.arange(0, W_grid * L_grid): # create evenly spaces variables \n\n    # Select a random number\n    index = np.random.randint(0, n_test)\n    # read and display an image with the selected index    \n    axes[i].imshow(X_test[index,1:])\n    label_index = int(y_pred[index])\n    axes[i].set_title(labels[label_index], fontsize = 8)\n    axes[i].axis('off')\n\nplt.subplots_adjust(hspace=0.4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_image(i, predictions_array, true_label, img):\n    predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n    plt.grid(False)\n    plt.xticks([])\n    plt.yticks([])\n\n    plt.imshow(img, cmap=plt.cm.binary)\n\n    predicted_label = np.argmax(predictions_array)\n    if predicted_label == true_label:\n        color = 'blue'\n    else:\n        color = 'red'\n\n    plt.xlabel(f\"{labels[int(predicted_label)]} {100*np.max(predictions_array):2.0f}% ({labels[int(true_label)]})\", \n               color=color)\n\ndef plot_value_array(i, predictions_array, true_label):\n    predictions_array, true_label = predictions_array, int(true_label[i])\n    plt.grid(False)\n    plt.xticks(range(10))\n    plt.yticks([])\n    thisplot = plt.bar(range(10), predictions_array, color=\"#777777\")\n    plt.ylim([0, 1])\n    predicted_label = np.argmax(predictions_array)\n\n    thisplot[predicted_label].set_color('red')\n    thisplot[true_label].set_color('blue')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model.predict(X_test)\n\n# Plot the first X test images, their predicted labels, and the true labels.\n# Color correct predictions in blue and incorrect predictions in red.\nnum_rows = 8\nnum_cols = 5\nnum_images = num_rows * num_cols\nplt.figure(figsize=(2 * 2 * num_cols, 2 * num_rows))\nfor i in range(num_images):\n    plt.subplot(num_rows, 2 * num_cols, 2 * i + 1)\n    plot_image(i, predictions[i], y_test, X_test)\n    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n    plot_value_array(i, predictions[i], y_test)\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. DenseNet model for image classification","metadata":{}},{"cell_type":"code","source":"from keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense\nfrom keras.models import Sequential\n\nmodel = Sequential()\nbase_model = DenseNet121(input_shape=(32, 32, 3), include_top=False, weights='imagenet', pooling='avg')\nmodel.add(base_model)\nmodel.add(Dense(10, activation='softmax'))\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nr = model.fit(train_generator, \n              epochs=100,\n              steps_per_epoch=steps_per_epoch,\n              validation_data=(X_test, y_cat_test), \n#               callbacks=[early_stop],\n             )","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 7. Save the models","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel.save('cnn_20_epochs.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}